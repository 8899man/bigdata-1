HBase 迁移数据
----

因搬迁机房需要，现需要在两个集群间迁移数据。这里记录下。

## 方法
有好几种方法用于不同HBase集群的数据迁移。可以参考[Importing Data Into HBase](http://www.cloudera.com/content/www/en-us/documentation/enterprise/latest/topics/admin_hbase_import.html)。这里大致说下。

- 如果数据是从一个HBase集群导入到另一个HBase集群：
  - 使用`snapshot`和`clone_snapshot`或`ExportSnapshot`方法；或`CopyTable`方法。
  - 若两个集群都不停机，可使用HBase的复制功能。
  - 或两个HBase版本不兼容，可使用DistCP和Import, Export配合迁移数据；或者升级HFile的。
- 若数据是从非HBase导入到HBase集群：
  - 将数据写入HFile格式，然后使用 `BulkLoad` 的导入到HBase。这种方法能绕开写路径，提交效率。
  - 使用pig之类工具将数据导入到HBase集群。 
- 使用流式数据导入到HBase集群：
  - 可以调用Java API或Thrift Proxy API写一个Java工具。
  - 通过REST Proxy API结合`wget`和`curl`将数据直接写入到HBase中。
  - 使用Flume或Spark。

### 使用CopyTable
CopyTable使用HBase的读路径或写路径拷贝当前集群中部分或全部的表到同一个/不同集群中的一个新表中。CopyTable的命令如下：

```shell
$ ./bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable --help 
Usage: CopyTable [general options] [--starttime=X] [--endtime=Y] [--new.name=NEW] [--peer.adr=ADR] <tablename>
```

若是拷贝到其它集群，指定`--peer.adr`。因为使用的是读路径和写路径，所以这种方式会引起读写压力。同时会造成切分Region。当然可通过预分区来避免过度的切分Region。由于snapshot操作在HDFS级别进行，HBase的HMaster和RS不参与操作，所以在CDH5中，大部分场景推荐用snapshots来代替copytable。

#### 实际操作
实际操作中，需要预先建好目标表，目标表和源表的表名和列族需相同，其他建表选项可不同。对于大表，最好做预分区；然后再执行copytable：

```
hbase org.apache.hadoop.hbase.mapreduce.CopyTable -Dhbase.client.scanner.caching=500 -Dmapred.output.compress=true -D mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec -Dmapred.map.tasks.speculative.execution=false --starttime=1448294400 --endtime=1448553600 --peer.adr=192.168.1.10:2181:/hbase $table_name
```

在执行命令过程中，可优化mapreduce参数来加快job的执行。注意，对于数据量特别大的表，可指定分时间和列族来减少数据量，避免脚本超时。

### 从CDH4拷贝数据到CDH5

CDH4和CDH5是不兼容的，因此`CopyTable`无法成功。可使用如下两种方法:

#### 配合Import和Export使用DistCP

- 在一个集群中，导出数据

```
hbase org.apache.hadoop.hbase.mapreduce.Export <tablename> /export_directory
```

- 将该数据从`/export_directory`拷贝到目标集群上

```
hadoop distcp -p -update -skipcrccheck hftp://cdh4-namenode:port/export_directory hdfs://cdh5-namenode/import_directory
```

默认端口为50070。


- 在目标集群上使用HBase Shell创建新表，表的列族同源集群
- 将目标集群hdfs中新拷贝的表导入到hbase中

```
hbase -Dhbase.import.version=0.94 org.apache.hadoop.hbase.mapreduce.Import t1 /import_directory
```

#### 升级HFile

**若替换整个`/hbase`目录的话，请注意先将新集群`/hbase`目录进行备份！** 

- 使用distcp将HFile文件从源集群拷贝至目标集群中
```
hadoop distcp -p -update -skipcrccheck webhdfs://cdh4-namenode:http-port/hbase hdfs://cdh5-namenode:rpc-port/hbase
```

- 在目标集群的CM中，在`Cluster > HBase`的`Action`菜单中选择`Upgrade HBase`.
- 启动目标集群

上述两种方法各有优缺点。前一种方法比较慢，当数据量大时，会耗时很久，~~后一种方法仅在目标集群为空时使用~~，后一种方式可指定到具体表名，同时由于操作的是HDFS，所以不会引起split等操作。

#### 实际操作

在源集群(CDH5.1)和目标集群(CDH5.5)上测试了下，由于版本号大致相同，所以不需要upgrade hbase操作。在拷贝数据过程中，因整个`/hbase`太大，可指定某个表，如`testTable`表，在操作前，先将源集群中表disable再flush: 

```
> disable 'testTable'
> flush 'testTable'
```
 
然后再进行copy，如：`HADOOP_USER_NAME=hbase hadoop distcp -Dmapreduce.job.name=copy_hbase -pb -update -delete -strategy dynamic webhdfs://10.10.3.10:50070/hbase/data/default/testTable webhdfs://192.168.1.10:50070/hbase/data/default/testTable`，由于该表的meta信息不存在，所以HBase无法识别testTable，通过`sudo -u hbase hbase hbck -repair`可解决meta缺失的问题。统计了下源表和目标表的行数是相等的，同时抽样看了些数据，也是相同的。

整体而言，这种方法利用集群特性，速度非常快，很适合大表。

### snapshot
快照保留的集群某个时间点的快照，同CopyTable/Export等相比，snapshot操作的仅仅是metadata，因此速度非常快。若是同集群拷贝，使用`clone_snapshot`进行拷贝，若是不同集群，可以使用`ExportSnapshot`进行拷贝。如下。

```
> hbase shell         
# 备份
> snapshot 'TestTable', 'TestTableSnapshot'          
# 使用clone_snapshot将某个表拷贝到同一集群中的其它表中
> clone_snapshot 'TestTableSnapshot', 'NewTestTable'  
```

若需要导出到其他HBase集群，可在shell中执行命令`sudo -u hbase hbase org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot <snap_name> -copy-to hdfs://<namenode>:8020/hbase -mappers 16`。正如上面据说，snapshot仅仅操作的是元数据，实际数据还是需要通过distcp拷贝过去。

一旦snapshot生成，snapshot中的数据将不会被删除，即使通过API显示删除也不行。

### 使用BulkLoad
HBase使用HFile格式存储文件，因此可以用程序将数据写成HFile格式，然后批量导入到HBase中。这种方式绕过写路径，有如下好处：

- 导入的数据能立即在HBase中可用，并不会产生额外的load和延迟
- 因为没使用WAL，所以不会触发flush和split操作
- 不会导致大量的GC操作

一般使用BulkLoad的过程如下：

- 从源数据外取出数据。如mysql数据库中使用`mysqldump`命令取出数据。如果数据为TSV或CSV格式，可跳过这步。
- 将第一步产生的数据处理为HFile格式。
- 每个region产生一个HFile文件。
- 借助[completebulkload](http://hbase.apache.org/book.html#completebulkload)将HFile文件导入到HBase中。

### 使用复制

HBase复制用于不同集群中复制数据，其以主推送的形式进行，即Master向各Slave推送数据。类似Mysql以Binlog进行复制，HBase的复制基于HLog（WAL）。复制是异步的，这意味主集群的修改不能马上在从集群上同步（最终一致性）。复制需要两个集群网络互通。开启复制的过程如下：

- 源集群hbase-site.xml中修改`hbase.replication`为`true`。
- 源集群在hbase shell中添加目标集群：`add_peer 'ID', 'CLUSTER_KEY'`。ID为必须为小整数，CLUSTER_KEY的形式为`hbase.zookeeper.quorum:hbase.zookeeper.property.clientPort:zookeeper.znode.parent`。
- 在源集群开启要复制的表或列族，将`REPLICATION_SCOPE`设置为1即可:
  ```
  hbase> disable 'TestTable'
  hbase> alter 'example_table', {NAME => 'example_family', REPLICATION_SCOPE => '1'}
  hbase> enable 'TestTable'
  ```
- 验证复制结果：
  ```
  hbase org.apache.hadoop.hbase.mapreduce.replication.VerifyReplication [--starttime=timestamp1] [--stoptime=timestamp] [--families=comma separated list of families] <peerId> <tablename>
  ```

#### 实际操作
在实际操作过程中，修改源目标集群后，需要重启HBase集群。

## 实践
在实际情况中，有集群A(0.98)和集群B(1.0)，现需要将集群A中的部分表拷贝到集群B中。

在集群B上的一个Yarn的gateway上执行如下脚本，其中distcp用了压缩。
```ssh
tmpdir="tmp/hbase_migrate"

# ssh到A集群Yarn的gateway上export表
ssh evans@A_GATEWAY_IP:PORT hbase org.apache.hadoop.hbase.mapreduce.Export -Dmapreduce.map.java.opts=-Xmx4g  -Dmapreduce.map.memory.mb=5000 $source_table_name hdfs://A_HDFS_IP:PORT/$tmpdir

# disctp from A to B
HADOOP_USER_NAME=hbase hadoop distcp -Dmapreduce.job.queuename=root.hadoop -Dmapreduce.job.name=hbase.${source_table_name} -update -delete -strategy dynamic -log /user/hbase/_distcplogs/tmp.$(date +%s).$RANDOM -update -delete webhdfs://A_IP:PORT/$tmpdir $tmpdir

# import
HADOOP_USER_NAME=hbase hbase -Dhbase.import.version=0.98 org.apache.hadoop.hbase.mapreduce.Import $source_table_name $tmpdir
```


参考：
---
- [Snapshots](https://hbase.apache.org/book.html#ops.snapshots)
- [distcp](https://hadoop.apache.org/docs/r1.0.4/cn/distcp.html)
- [Online Apache HBase Backups with CopyTable](http://blog.cloudera.com/blog/2012/06/online-hbase-backups-with-copytable-2/)
- [Approaches to Backup and Disaster Recovery in HBase](http://blog.cloudera.com/blog/2013/11/approaches-to-backup-and-disaster-recovery-in-hbase/)
- [HBase replication](http://www.cloudera.com/documentation/enterprise/latest/topics/cdh_bdr_hbase_replication.html)
